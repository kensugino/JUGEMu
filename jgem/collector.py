"""

.. module:: collector
    :synopsis: Calculate and collect coverages for all samples against a specific assembly.

..  moduleauthor:: Ken Sugino <ken.sugino@gmail.com>

"""
# system imports
import os
from collections import Counter
from operator import iadd
from functools import reduce
import logging
logging.basicConfig(level=logging.DEBUG)
LOG = logging.getLogger(__name__)

# 3rd party libraries
import pandas as PD
import numpy as N
#import matplotlib.pyplot as P

# library imports
from jgem import utils as UT
from jgem import gtfgffbed as GGB
from jgem import bedtools as BT
#from jgem import bigwig as BW
from jgem import trimex as TE
from jgem import filenames as FN
from jgem import calccov as CC


class CollectorNames(FN.FileNamesBase):

    def __init__(self, samplecode, sampleinfo, assemblycode, outdir):
        self.si = sampleinfo
        self.samplecode = samplecode
        self.assemblycode = assemblycode
        self.outdir = outdir

        #prefix = os.path.join(outdir, '{0}.{1}'.format(assemblycode, samplecode))
        prefix = os.path.join(outdir, assemblycode)
        super(CollectorNames, self).__init__(prefix)

    def txtname2(self, scode, kind, category='output'):
        return self.txtname('{0}.{1}'.format(scode, kind), category=category)

    def txtname1(self, kind, category='output'):
        return self.txtname2(self.samplecode, kind, category)


class Collector(object):
    """ Calculate and collect coverages for all samples against specified assembly.
    For large datasets, calculations of gcov/ecov/gcov1000 should be done separately
    using a cluster of computers. T

    Args:
    	assemblyprefix: assembly prefix path (+.ex.txt.gz,.sj.txt.gz)
    	assemblycode: identifier for the assembly
    	sampleinfo: dataframe containing sample info (required fileds= name, bwfile, sjfile)
        samplecode: identidier for the sample set
        outdir: output directory

   	Methods:
	    1. collect_gcov: gene coverages (row:genes, col:samples)
	    2. collect_ecov: exon coverages (row:exons, col:samples)
	    3. collect_jcnt: junction counts (row:junctions, col:samples)
	    4. collect_gcov1000 (using trimmed model)

    Outputs:
        are written in files
        1. outdir/assemblycode.samplecode.gcov.txt.gz
        1b. outdir/assemblycode.samplecode.ugcov.txt.gz
        2. outdir/assemblycode.samplecode.ecov.txt.gz
        2b. outdir/assemblycode.samplecode.uecov.txt.gz
        3. outdir/assemblycode.samplecode.jcnt.txt.gz
        4. outdir/assemblycode.samplecode.t1000gcov.txt.gz
        4b. outdir/assemblycode.samplecode.ut1000gcov.txt.gz

        Individual sample gcov/ecov/gcov1000 should have filename
        outdir/assemblycode.samplename.gcov.txt.gz etc.
        If these files are generated by separate cluster computation, 
        this object will skip computation and just collect results.

    """
    def __init__(self, assemblycode, assemblyprefix, samplecode, sampleinfo, outdir):
        self.acode = assemblycode
        self.apre = assemblyprefix
        self.expath = assemblyprefix+'.ex.txt.gz'
        self.sjpath = assemblyprefix+'.sj.txt.gz'
        self.cipath = assemblyprefix+'.ci.txt.gz'
        if not os.path.exists(self.expath):
            raise ValueError('{0} does not exists'.format(self.expath))
        if not os.path.exists(self.sjpath):
            raise ValueError('{0} does not exists'.format(self.sjpath))
        if not os.path.exists(self.cipath):
            LOG.info('generating CI:{0}...'.format(self.cipath))
            self.mex = UT.read_pandas(self.expath)
            self.ci = UT.chopintervals(self.mex, self.cipath)
        self.si = sampleinfo
        self.scode = samplecode 
        self.fnobj = CollectorNames(samplecode, sampleinfo, assemblycode, outdir)
        
    def ex(self):
        """ assembly ex dataframe """
        if not hasattr(self, 'mex'):
            self.mex = UT.read_pandas(self.expath)
        return self.mex

    def sj(self):
        """ assembly sj dataframe """
        if not hasattr(self, 'msj'):
            self.msj = UT.read_pandas(self.sjpath)
        return self.msj

    # TODO: split into chromosome and collect in separate CPU?
    def collect_jcnt(self, which='jcnt'):
        """ which = ucnt, mcnt, jcnt(=ucnt or mcnt) """
        msj = self.sj()
        fn = self.fnobj
        msj['locus'] = UT.calc_locus_strand(msj)
        for i, (s,sjfile) in enumerate(self.si[['name','sjbed_path']].values):
            LOG.info('{1}/{2} processing {0}'.format(s,i,len(self.si)))
            sj = GGB.read_sj(sjfile)
            sj['locus'] = UT.calc_locus_strand(sj)
            if which == 'jcnt':
                sj['jcnt'] = [x or y for x,y in sj[['ucnt','mcnt']].values]
            l2u = UT.df2dict(sj, 'locus', which)
            msj[s] = [l2u.get(x,0) for x in msj['locus']]
        UT.write_pandas(msj, fn.txtname1(which),'h')
        
    # TODO change to IPython parallel if iparallel=True
    # need to launch each engine with np CPU 
    def collect_ecov(self,unique=False, np=4, iparallel=False):
        """ Collect/calculate exon coverages.

        If unique=True uses bigwig file with .uniq.bw suffix instead of .bw. 

        """
        mex = self.ex()
        fn = self.fnobj
        w = 'uecov' if unique else 'ecov'
        dpre = fn.fname('')
        ep = self.expath
        cp = self.cipath
        ids = mex['_id'].values
        args = [(s, w, bw, dpre, ep, cp, ids, np) for s,bw in self.si[['name','bw_path']].values]
        for i,a in enumerate(args):
            LOG.info('{1}/{2} processing {0}'.format(a[0],i,len(args)))
            # path = fn.txtname2(a[0], a[1]) # register path
            s, ecov = _calc_ecov_worker(*a)
            mex[s] = ecov
        UT.write_pandas(mex, fn.txtname1(w), 'h')
        
    def collect_gcov(self,unique=False, np=4, iparallel=False):
        """ Collect/calculate gene coverages.

        If unique=True uses bigwig file with .uniq.bw suffix instead of .bw. 

        """
        mex = self.ex()
        fn = self.fnobj
        w = 'ugcov' if unique else 'gcov'
        tmp = mex.groupby('_gidx')
        self.gcov1 = gcov1 = tmp[['chr']].first().reset_index().sort_values('_gidx')
        self.gcov2 = gcov2 = gcov1.copy()
        ids = gcov1['_gidx'].values
        dpre = fn.fname('')
        ep = self.expath
        cp = self.cipath
        args = [(s, w, bw, dpre, ep, cp, ids, np) for s,bw in self.si[['name','bw_path']].values]
        for i,a in enumerate(args):
            LOG.info('{1}/{2} processing {0}'.format(a[0],i,len(args)))
            # path = fn.txtname2(a[0], a[1]) # register path
            s, gcov = _calc_gcov_worker(*a)
            gcov1[s] = gcov['gcov'].values
            gcov2[s] = gcov['gcov2'].values
        # copy st,ed,glen
        gcov1['len'] = gcov['len'].values
        gcov2['len'] = gcov['len'].values
        gcov1['st'] = gcov['st'].values
        gcov2['st'] = gcov['st'].values
        gcov1['ed'] = gcov['ed'].values
        gcov2['ed'] = gcov['ed'].values
        UT.write_pandas(gcov1, fn.txtname1(w), 'h')
        UT.write_pandas(gcov2, fn.txtname1(w+'2'), 'h')
        
    def trimex(self, length, np=4):
        expath = self.expath
        texpath = self.apre+'.trimmed{0}.ex.txt.gz'.format(length)
        tcipath = self.apre+'.trimmed{0}.ci.txt.gz'.format(length)
        if not os.path.exists(texpath):
            TE.trim_ex(expath, texpath, tcipath, length=length, gidfld='_gidx', np=np)
        if not os.path.exists(tcipath):
            tex = UT.read_pandas(texpath)
            UT.chopintervals(tex, tcipath)
        return texpath, tcipath

    def collect_gcov1000(self,unique=True, np=4, iparallel=False):
        """ Collect/calculate gene coverages. Uses trimmed model (1000bp from 3'end)

        If unique=True uses bigwig file with .uniq.bw suffix instead of .bw. 

        """
        self.collect_gcov_length(unique, 1000, np, iparallel)

    def collect_gcov_length(self, unique=True, length=1000, np=4, iparallel=False):
        """ Collect/calculate gene coverages. Uses trimmed model (1000bp from 3'end)

        If unique=True uses bigwig file with .uniq.bw suffix instead of .bw. 

        """
        mex = self.ex()
        fn = self.fnobj
        code = 't{0}gcov'.format(length)
        w = 'u'+code if unique else code
        tmp = mex.groupby('_gidx')
        self.gcov1 = gcov1 = tmp[['chr']].first().reset_index().sort_values('_gidx')
        ids = gcov1['_gidx'].values
        dpre = fn.fname('')
        # make trimmed ex if not exists
        ep,cp = self.trimex(length)
        args = [(s, w, bw, dpre, ep, cp, ids, np) for s,bw in self.si[['name','bw_path']].values]
        for i,a in enumerate(args):
            LOG.info('{1}/{2} processing {0}'.format(a[0],i,len(args)))
            # path = fn.txtname2(a[0], a[1]) # register path
            s, gcov = _calc_gcov_worker(*a)
            gcov1[s] = gcov['gcov'].values
        gcov1['len'] = gcov['len'].values
        gcov1['st'] = gcov['st'].values
        gcov1['ed'] = gcov['ed'].values
        UT.write_pandas(gcov1, fn.txtname1(w), 'h')

    def collect_all(self, np=4):
        self.collect_jcnt()
        self.collect_ecov(np=np)
        self.collect_gcov(np=np)
        
    def collect_unique(self, np=4):
        self.collect_ecov(unique=True, np=np)
        self.collect_gcov(unique=True, np=np)


def _calc_ecov_worker(sname, which, bwfile, dstpre, expath, cipath, ids, np):
    pre = which[:-len('ecov')] # 'u' or ''
    if len(pre)>0 and pre[0]=='u':
        unique = True
    else:
        unique = False
    path = dstpre+sname+'.'+which
    if os.path.exists(path):
        ecov = UT.read_pandas(path)
    else: # calculate gcov
        if unique:
            bwfile = bwfile.replace('.bw','.uniq.bw')    
            LOG.debug('using unique bigwig {0}'.format(bwfile))
        ecov = CC.calc_ecov(
            expath=expath,
            cipath=cipath,
            bwpath=bwfile, 
            dstprefix=dstpre+sname+'.'+pre,
            override=False, # reuse covci from ecov calc
            np=np)
    ar = ecov.set_index('eid').ix[ids]['ecov'].values # numpy array
    return sname, ar

def _calc_gcov_worker(sname, which, bwfile, dstpre, expath, cipath, ids, np):
    pre = which[:-len('gcov')] # 'u' or '' or 't1000' or 'ut1000'
    if len(pre)>0 and pre[0]=='u':
        unique = True
    else:
        unique = False
    path = dstpre+sname+'.'+which
    if os.path.exists(path) and (not override):
        gcov = UT.read_pandas(path)
    else: # calculate gcov
        if unique:
            bwfile = bwfile.replace('.bw','.uniq.bw')    
            LOG.debug('using unique bigwig {0}'.format(bwfile))
        gcov = CC.calc_gcov(
            expath=expath,
            cipath=cipath,
            bwpath=bwfile, 
            dstprefix=dstpre+sname+'.'+pre,
            override=False, # reuse covci from ecov calc
            np=np)
    df = gcov.set_index('_gidx').ix[ids][['gcov','gcov2','len','st','ed']] # dataframe
    return sname, df

